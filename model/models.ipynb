{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa4eebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "532a3123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\VII\\ANT\\model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786b4252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data ---\n",
    "# IMPORTANT: Replace 'your_dataset.csv' with the actual path to your CSE-CIC-IDS2018 dataset file.\n",
    "try:\n",
    "    df = pd.read_csv('../data\\combined_realistic.csv')\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset file not found. Please update the file path.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30abf344",
   "metadata": {},
   "source": [
    "#### Filtered Dataset CSV, taken from 30 features that were decided in further cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60cfe80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of top 30 features you identified\n",
    "top_30_features = [\n",
    "    'Init Fwd Win Byts', 'Fwd Seg Size Min', 'Dst Port', 'Fwd Header Len', 'Flow IAT Min', \n",
    "    'Flow Duration', 'Fwd IAT Max', 'Fwd IAT Min', 'Fwd Pkts/s', 'Flow Pkts/s', \n",
    "    'Fwd IAT Tot', 'Flow IAT Max', 'Fwd Pkt Len Mean', 'Fwd IAT Mean', 'Flow IAT Mean', \n",
    "    'Bwd Pkts/s', 'Pkt Len Mean', 'TotLen Fwd Pkts', 'Flow Byts/s', 'Init Bwd Win Byts', \n",
    "    'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Bwd Pkt Len Max', 'Pkt Len Var', \n",
    "    'Fwd Seg Size Avg', 'Tot Fwd Pkts', 'Bwd Header Len', 'Pkt Len Max', \n",
    "    'Subflow Fwd Byts', 'Subflow Fwd Pkts'\n",
    "]\n",
    "\n",
    "# Create the final list of columns to keep\n",
    "columns_to_keep = top_30_features + ['Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba737600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering the existing DataFrame in memory...\n",
      "New subset DataFrame created successfully.\n",
      "Saving the new dataset to '../data/filtered_dataset.csv'...\n",
      "\n",
      "Script finished successfully! ðŸŽ‰\n",
      "Your new file '../data/filtered_dataset.csv' is ready to use.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Filter the DataFrame ---\n",
    "print(\"Filtering the existing DataFrame in memory...\")\n",
    "\n",
    "# Best practice: Clean column names to avoid errors\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Create the new subset DataFrame by selecting only the columns you need\n",
    "df_subset = df[columns_to_keep]\n",
    "\n",
    "print(\"New subset DataFrame created successfully.\")\n",
    "\n",
    "# --- 3. Save the New, Smaller Dataset ---\n",
    "filtered_filename = '../data/filtered_dataset.csv'\n",
    "print(f\"Saving the new dataset to '{filtered_filename}'...\")\n",
    "\n",
    "# Using index=False prevents pandas from writing an unnecessary row index\n",
    "df_subset.to_csv(filtered_filename, index=False)\n",
    "\n",
    "print(\"\\nScript finished successfully! ðŸŽ‰\")\n",
    "print(f\"Your new file '{filtered_filename}' is ready to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df7a282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8192732 entries, 0 to 8229038\n",
      "Data columns (total 79 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Dst Port           int64  \n",
      " 1   Protocol           int64  \n",
      " 2   Flow Duration      int64  \n",
      " 3   Tot Fwd Pkts       int64  \n",
      " 4   Tot Bwd Pkts       int64  \n",
      " 5   TotLen Fwd Pkts    int64  \n",
      " 6   TotLen Bwd Pkts    float64\n",
      " 7   Fwd Pkt Len Max    int64  \n",
      " 8   Fwd Pkt Len Min    int64  \n",
      " 9   Fwd Pkt Len Mean   float64\n",
      " 10  Fwd Pkt Len Std    float64\n",
      " 11  Bwd Pkt Len Max    int64  \n",
      " 12  Bwd Pkt Len Min    int64  \n",
      " 13  Bwd Pkt Len Mean   float64\n",
      " 14  Bwd Pkt Len Std    float64\n",
      " 15  Flow Byts/s        float64\n",
      " 16  Flow Pkts/s        float64\n",
      " 17  Flow IAT Mean      float64\n",
      " 18  Flow IAT Std       float64\n",
      " 19  Flow IAT Max       float64\n",
      " 20  Flow IAT Min       float64\n",
      " 21  Fwd IAT Tot        float64\n",
      " 22  Fwd IAT Mean       float64\n",
      " 23  Fwd IAT Std        float64\n",
      " 24  Fwd IAT Max        float64\n",
      " 25  Fwd IAT Min        float64\n",
      " 26  Bwd IAT Tot        float64\n",
      " 27  Bwd IAT Mean       float64\n",
      " 28  Bwd IAT Std        float64\n",
      " 29  Bwd IAT Max        float64\n",
      " 30  Bwd IAT Min        float64\n",
      " 31  Fwd PSH Flags      int64  \n",
      " 32  Bwd PSH Flags      int64  \n",
      " 33  Fwd URG Flags      int64  \n",
      " 34  Bwd URG Flags      int64  \n",
      " 35  Fwd Header Len     int64  \n",
      " 36  Bwd Header Len     int64  \n",
      " 37  Fwd Pkts/s         float64\n",
      " 38  Bwd Pkts/s         float64\n",
      " 39  Pkt Len Min        int64  \n",
      " 40  Pkt Len Max        int64  \n",
      " 41  Pkt Len Mean       float64\n",
      " 42  Pkt Len Std        float64\n",
      " 43  Pkt Len Var        float64\n",
      " 44  FIN Flag Cnt       int64  \n",
      " 45  SYN Flag Cnt       int64  \n",
      " 46  RST Flag Cnt       int64  \n",
      " 47  PSH Flag Cnt       int64  \n",
      " 48  ACK Flag Cnt       int64  \n",
      " 49  URG Flag Cnt       int64  \n",
      " 50  CWE Flag Count     int64  \n",
      " 51  ECE Flag Cnt       int64  \n",
      " 52  Down/Up Ratio      int64  \n",
      " 53  Pkt Size Avg       float64\n",
      " 54  Fwd Seg Size Avg   float64\n",
      " 55  Bwd Seg Size Avg   float64\n",
      " 56  Fwd Byts/b Avg     int64  \n",
      " 57  Fwd Pkts/b Avg     int64  \n",
      " 58  Fwd Blk Rate Avg   int64  \n",
      " 59  Bwd Byts/b Avg     int64  \n",
      " 60  Bwd Pkts/b Avg     int64  \n",
      " 61  Bwd Blk Rate Avg   int64  \n",
      " 62  Subflow Fwd Pkts   int64  \n",
      " 63  Subflow Fwd Byts   int64  \n",
      " 64  Subflow Bwd Pkts   int64  \n",
      " 65  Subflow Bwd Byts   int64  \n",
      " 66  Init Fwd Win Byts  int64  \n",
      " 67  Init Bwd Win Byts  int64  \n",
      " 68  Fwd Act Data Pkts  int64  \n",
      " 69  Fwd Seg Size Min   int64  \n",
      " 70  Active Mean        float64\n",
      " 71  Active Std         float64\n",
      " 72  Active Max         float64\n",
      " 73  Active Min         float64\n",
      " 74  Idle Mean          float64\n",
      " 75  Idle Std           float64\n",
      " 76  Idle Max           float64\n",
      " 77  Idle Min           float64\n",
      " 78  Label              object \n",
      "dtypes: float64(37), int64(41), object(1)\n",
      "memory usage: 4.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81c49381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Data Cleaning & Preprocessing ---\n",
    "print(\"Cleaning and preprocessing data...\")\n",
    "\n",
    "# Drop the timestamp column as it's not a useful feature in its raw format\n",
    "if 'Timestamp' in df.columns:\n",
    "    df = df.drop(columns=['Timestamp'])\n",
    "\n",
    "# Clean column names (strip leading/trailing spaces)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# The dataset is known to have infinity and NaN values.\n",
    "# Replace infinite values with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# Drop rows with NaN values. For this dataset, this is a safe approach.\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d414524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8192732 entries, 0 to 8229038\n",
      "Data columns (total 79 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Dst Port           int64  \n",
      " 1   Protocol           int64  \n",
      " 2   Flow Duration      int64  \n",
      " 3   Tot Fwd Pkts       int64  \n",
      " 4   Tot Bwd Pkts       int64  \n",
      " 5   TotLen Fwd Pkts    int64  \n",
      " 6   TotLen Bwd Pkts    float64\n",
      " 7   Fwd Pkt Len Max    int64  \n",
      " 8   Fwd Pkt Len Min    int64  \n",
      " 9   Fwd Pkt Len Mean   float64\n",
      " 10  Fwd Pkt Len Std    float64\n",
      " 11  Bwd Pkt Len Max    int64  \n",
      " 12  Bwd Pkt Len Min    int64  \n",
      " 13  Bwd Pkt Len Mean   float64\n",
      " 14  Bwd Pkt Len Std    float64\n",
      " 15  Flow Byts/s        float64\n",
      " 16  Flow Pkts/s        float64\n",
      " 17  Flow IAT Mean      float64\n",
      " 18  Flow IAT Std       float64\n",
      " 19  Flow IAT Max       float64\n",
      " 20  Flow IAT Min       float64\n",
      " 21  Fwd IAT Tot        float64\n",
      " 22  Fwd IAT Mean       float64\n",
      " 23  Fwd IAT Std        float64\n",
      " 24  Fwd IAT Max        float64\n",
      " 25  Fwd IAT Min        float64\n",
      " 26  Bwd IAT Tot        float64\n",
      " 27  Bwd IAT Mean       float64\n",
      " 28  Bwd IAT Std        float64\n",
      " 29  Bwd IAT Max        float64\n",
      " 30  Bwd IAT Min        float64\n",
      " 31  Fwd PSH Flags      int64  \n",
      " 32  Bwd PSH Flags      int64  \n",
      " 33  Fwd URG Flags      int64  \n",
      " 34  Bwd URG Flags      int64  \n",
      " 35  Fwd Header Len     int64  \n",
      " 36  Bwd Header Len     int64  \n",
      " 37  Fwd Pkts/s         float64\n",
      " 38  Bwd Pkts/s         float64\n",
      " 39  Pkt Len Min        int64  \n",
      " 40  Pkt Len Max        int64  \n",
      " 41  Pkt Len Mean       float64\n",
      " 42  Pkt Len Std        float64\n",
      " 43  Pkt Len Var        float64\n",
      " 44  FIN Flag Cnt       int64  \n",
      " 45  SYN Flag Cnt       int64  \n",
      " 46  RST Flag Cnt       int64  \n",
      " 47  PSH Flag Cnt       int64  \n",
      " 48  ACK Flag Cnt       int64  \n",
      " 49  URG Flag Cnt       int64  \n",
      " 50  CWE Flag Count     int64  \n",
      " 51  ECE Flag Cnt       int64  \n",
      " 52  Down/Up Ratio      int64  \n",
      " 53  Pkt Size Avg       float64\n",
      " 54  Fwd Seg Size Avg   float64\n",
      " 55  Bwd Seg Size Avg   float64\n",
      " 56  Fwd Byts/b Avg     int64  \n",
      " 57  Fwd Pkts/b Avg     int64  \n",
      " 58  Fwd Blk Rate Avg   int64  \n",
      " 59  Bwd Byts/b Avg     int64  \n",
      " 60  Bwd Pkts/b Avg     int64  \n",
      " 61  Bwd Blk Rate Avg   int64  \n",
      " 62  Subflow Fwd Pkts   int64  \n",
      " 63  Subflow Fwd Byts   int64  \n",
      " 64  Subflow Bwd Pkts   int64  \n",
      " 65  Subflow Bwd Byts   int64  \n",
      " 66  Init Fwd Win Byts  int64  \n",
      " 67  Init Bwd Win Byts  int64  \n",
      " 68  Fwd Act Data Pkts  int64  \n",
      " 69  Fwd Seg Size Min   int64  \n",
      " 70  Active Mean        float64\n",
      " 71  Active Std         float64\n",
      " 72  Active Max         float64\n",
      " 73  Active Min         float64\n",
      " 74  Idle Mean          float64\n",
      " 75  Idle Std           float64\n",
      " 76  Idle Max           float64\n",
      " 77  Idle Min           float64\n",
      " 78  Label              object \n",
      "dtypes: float64(37), int64(41), object(1)\n",
      "memory usage: 4.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c5820a",
   "metadata": {},
   "source": [
    "#### Checking on how the Flags are in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edc92e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"FIN Flag Cnt\",\n",
    "    \"SYN Flag Cnt\",\n",
    "    \"RST Flag Cnt\",\n",
    "    \"PSH Flag Cnt\",\n",
    "    \"ACK Flag Cnt\",\n",
    "    \"URG Flag Cnt\",\n",
    "    \"CWE Flag Count\",\n",
    "    \"ECE Flag Cnt\"\n",
    "]\n",
    "\n",
    "df_flags = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1187ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIN Flag Cnt</th>\n",
       "      <th>SYN Flag Cnt</th>\n",
       "      <th>RST Flag Cnt</th>\n",
       "      <th>PSH Flag Cnt</th>\n",
       "      <th>ACK Flag Cnt</th>\n",
       "      <th>URG Flag Cnt</th>\n",
       "      <th>CWE Flag Count</th>\n",
       "      <th>ECE Flag Cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8229034</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8229035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8229036</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8229037</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8229038</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8192732 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FIN Flag Cnt  SYN Flag Cnt  RST Flag Cnt  PSH Flag Cnt  ACK Flag Cnt  \\\n",
       "0                   0             0             0             0             0   \n",
       "1                   0             0             0             0             0   \n",
       "2                   0             0             0             0             0   \n",
       "3                   0             0             0             1             0   \n",
       "4                   0             0             0             1             0   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "8229034             0             0             1             1             0   \n",
       "8229035             0             0             1             1             0   \n",
       "8229036             0             0             1             1             0   \n",
       "8229037             0             0             1             1             0   \n",
       "8229038             0             0             1             1             0   \n",
       "\n",
       "         URG Flag Cnt  CWE Flag Count  ECE Flag Cnt  \n",
       "0                   0               0             0  \n",
       "1                   0               0             0  \n",
       "2                   0               0             0  \n",
       "3                   0               0             0  \n",
       "4                   0               0             0  \n",
       "...               ...             ...           ...  \n",
       "8229034             0               0             1  \n",
       "8229035             0               0             1  \n",
       "8229036             0               0             1  \n",
       "8229037             0               0             1  \n",
       "8229038             0               0             1  \n",
       "\n",
       "[8192732 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e6b3a9",
   "metadata": {},
   "source": [
    "#### Feature Selection of top 30 models based on feature importance using RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaefa063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features and labels...\n",
      "Training a RandomForest model to find important features...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">50</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 3. Feature and Label Preparation ---\n",
    "print(\"Preparing features and labels...\")\n",
    "X = df.drop(columns=['Label'])\n",
    "y = df['Label']\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# --- 4. Train a Model for Feature Importance ---\n",
    "print(\"Training a RandomForest model to find important features...\")\n",
    "# We don't need to scale the data for a RandomForest's feature importance\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "model.fit(X, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc97c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting top 30 features...\n",
      "\n",
      "--- Top 30 Most Important Features ---\n",
      "['Init Fwd Win Byts', 'Fwd Seg Size Min', 'Dst Port', 'Fwd Header Len', 'Flow IAT Min', 'Flow Duration', 'Fwd IAT Max', 'Fwd IAT Min', 'Fwd Pkts/s', 'Flow Pkts/s', 'Fwd IAT Tot', 'Flow IAT Max', 'Fwd Pkt Len Mean', 'Fwd IAT Mean', 'Flow IAT Mean', 'Bwd Pkts/s', 'Pkt Len Mean', 'TotLen Fwd Pkts', 'Flow Byts/s', 'Init Bwd Win Byts', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Bwd Pkt Len Max', 'Pkt Len Var', 'Fwd Seg Size Avg', 'Tot Fwd Pkts', 'Bwd Header Len', 'Pkt Len Max', 'Subflow Fwd Byts', 'Subflow Fwd Pkts']\n",
      "\n",
      "Script finished successfully! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Get and Print Top Features ---\n",
    "print(\"Extracting top 30 features...\")\n",
    "\n",
    "# Create a dataframe of features and their importance scores\n",
    "importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Get the top 30 feature names\n",
    "top_30_features = feature_importance_df.head(30)['feature'].tolist()\n",
    "\n",
    "print(\"\\n--- Top 30 Most Important Features ---\")\n",
    "# Print the list in a format that's easy to copy and paste\n",
    "print(repr(top_30_features))\n",
    "\n",
    "print(\"\\nScript finished successfully! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f0181a",
   "metadata": {},
   "source": [
    "#### Model Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d10314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 30 available features for modeling.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Feature Selection & Label Prep ---\n",
    "# Using a representative list of top 30 features from this dataset.\n",
    "# Replace this with the exact list from your feature selection script if different.\n",
    "top_30_features = ['Init Fwd Win Byts', 'Fwd Seg Size Min', 'Dst Port', \n",
    "'Fwd Header Len', 'Flow IAT Min', 'Flow Duration', 'Fwd IAT Max', 'Fwd IAT Min', \n",
    "'Fwd Pkts/s', 'Flow Pkts/s', 'Fwd IAT Tot', 'Flow IAT Max', 'Fwd Pkt Len Mean', \n",
    "'Fwd IAT Mean', 'Flow IAT Mean', 'Bwd Pkts/s', 'Pkt Len Mean', 'TotLen Fwd Pkts', \n",
    "'Flow Byts/s', 'Init Bwd Win Byts', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', \n",
    "'Bwd Pkt Len Max', 'Pkt Len Var', 'Fwd Seg Size Avg', 'Tot Fwd Pkts', 'Bwd Header Len',\n",
    " 'Pkt Len Max', 'Subflow Fwd Byts', 'Subflow Fwd Pkts']\n",
    "\n",
    "\n",
    "# Ensure all selected features are present in the dataframe\n",
    "top_30_features = [f for f in top_30_features if f in df.columns]\n",
    "print(f\"Using {len(top_30_features)} available features for modeling.\")\n",
    "\n",
    "X = df[top_30_features]\n",
    "y = df['Label']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a59b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Split and Scale Data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7faecf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Initialize Models ---\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "model_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcb2617c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Logistic Regression ---\n",
      "--- Evaluating Logistic Regression ---\n",
      "\n",
      "Training Accuracy for Logistic Regression: 0.9439\n",
      "Testing Accuracy for Logistic Regression: 0.9438\n",
      "Classification Report for Logistic Regression (on Test Data):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                  Benign       0.95      0.99      0.97   1215429\n",
      "                     Bot       0.82      0.50      0.62     57238\n",
      "        DDOS attack-HOIC       0.98      1.00      0.99    137203\n",
      "        DoS attacks-Hulk       0.99      1.00      0.99     92382\n",
      "DoS attacks-SlowHTTPTest       0.65      0.55      0.60     27978\n",
      "          FTP-BruteForce       0.71      0.78      0.74     38671\n",
      "           Infilteration       0.26      0.00      0.01     32128\n",
      "          SSH-Bruteforce       0.99      1.00      0.99     37518\n",
      "\n",
      "                accuracy                           0.94   1638547\n",
      "               macro avg       0.79      0.73      0.74   1638547\n",
      "            weighted avg       0.93      0.94      0.93   1638547\n",
      "\n",
      "\n",
      "--- Training Random Forest ---\n",
      "--- Evaluating Random Forest ---\n",
      "\n",
      "Training Accuracy for Random Forest: 0.9797\n",
      "Testing Accuracy for Random Forest: 0.9644\n",
      "Classification Report for Random Forest (on Test Data):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                  Benign       0.98      0.99      0.98   1215429\n",
      "                     Bot       1.00      1.00      1.00     57238\n",
      "        DDOS attack-HOIC       1.00      1.00      1.00    137203\n",
      "        DoS attacks-Hulk       1.00      1.00      1.00     92382\n",
      "DoS attacks-SlowHTTPTest       0.77      0.51      0.62     27978\n",
      "          FTP-BruteForce       0.72      0.89      0.79     38671\n",
      "           Infilteration       0.21      0.10      0.13     32128\n",
      "          SSH-Bruteforce       1.00      1.00      1.00     37518\n",
      "\n",
      "                accuracy                           0.96   1638547\n",
      "               macro avg       0.83      0.81      0.82   1638547\n",
      "            weighted avg       0.96      0.96      0.96   1638547\n",
      "\n",
      "\n",
      "--- Training XGBoost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VII\\ANT\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating XGBoost ---\n",
      "\n",
      "Training Accuracy for XGBoost: 0.9697\n",
      "Testing Accuracy for XGBoost: 0.9696\n",
      "Classification Report for XGBoost (on Test Data):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                  Benign       0.98      1.00      0.99   1215429\n",
      "                     Bot       1.00      1.00      1.00     57238\n",
      "        DDOS attack-HOIC       1.00      1.00      1.00    137203\n",
      "        DoS attacks-Hulk       1.00      1.00      1.00     92382\n",
      "DoS attacks-SlowHTTPTest       0.77      0.51      0.62     27978\n",
      "          FTP-BruteForce       0.72      0.89      0.79     38671\n",
      "           Infilteration       0.55      0.03      0.06     32128\n",
      "          SSH-Bruteforce       1.00      1.00      1.00     37518\n",
      "\n",
      "                accuracy                           0.97   1638547\n",
      "               macro avg       0.88      0.80      0.81   1638547\n",
      "            weighted avg       0.96      0.97      0.96   1638547\n",
      "\n",
      "\n",
      "--- Training LightGBM ---\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.455995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7387\n",
      "[LightGBM] [Info] Number of data points in the train set: 6554185, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score -0.298712\n",
      "[LightGBM] [Info] Start training from score -3.354342\n",
      "[LightGBM] [Info] Start training from score -2.480109\n",
      "[LightGBM] [Info] Start training from score -2.875627\n",
      "[LightGBM] [Info] Start training from score -4.070146\n",
      "[LightGBM] [Info] Start training from score -3.746481\n",
      "[LightGBM] [Info] Start training from score -3.931845\n",
      "[LightGBM] [Info] Start training from score -3.776751\n",
      "--- Evaluating LightGBM ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VII\\ANT\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\VII\\ANT\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy for LightGBM: 0.9716\n",
      "Testing Accuracy for LightGBM: 0.9715\n",
      "Classification Report for LightGBM (on Test Data):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                  Benign       0.97      1.00      0.99   1215429\n",
      "                     Bot       1.00      1.00      1.00     57238\n",
      "        DDOS attack-HOIC       1.00      1.00      1.00    137203\n",
      "        DoS attacks-Hulk       1.00      1.00      1.00     92382\n",
      "DoS attacks-SlowHTTPTest       0.91      0.53      0.66     27978\n",
      "          FTP-BruteForce       0.74      0.96      0.83     38671\n",
      "           Infilteration       0.59      0.03      0.05     32128\n",
      "          SSH-Bruteforce       1.00      1.00      1.00     37518\n",
      "\n",
      "                accuracy                           0.97   1638547\n",
      "               macro avg       0.90      0.81      0.82   1638547\n",
      "            weighted avg       0.97      0.97      0.96   1638547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # --- 6. Train and Evaluate Each Model ---\n",
    "# for name, model in models.items():\n",
    "#     print(f\"\\n--- Training {name} ---\")\n",
    "#     model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "#     print(f\"--- Evaluating {name} ---\")\n",
    "#     y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     model_results[name] = accuracy\n",
    "    \n",
    "#     print(f\"\\nAccuracy for {name}: {accuracy:.4f}\")\n",
    "#     print(f\"Classification Report for {name}:\")\n",
    "#     print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# --- 6. Train and Evaluate Each Model ---\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- Training {name} ---\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(f\"--- Evaluating {name} ---\")\n",
    "    \n",
    "    # 1. Calculate Training Accuracy (NEW)\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    \n",
    "    # 2. Calculate Testing Accuracy (Original)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    model_results[name] = test_accuracy # We still judge the model on its test accuracy\n",
    "    \n",
    "    # 3. Print both (NEW)\n",
    "    print(f\"\\nTraining Accuracy for {name}: {train_accuracy:.4f}\")\n",
    "    print(f\"Testing Accuracy for {name}: {test_accuracy:.4f}\")\n",
    "    \n",
    "    print(f\"Classification Report for {name} (on Test Data):\")\n",
    "    print(classification_report(y_test, y_test_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53f612dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Comparison Summary ---\n",
      "                     Accuracy\n",
      "LightGBM             0.971511\n",
      "XGBoost              0.969581\n",
      "Random Forest        0.964376\n",
      "Logistic Regression  0.943799\n",
      "\n",
      "Best performing model is: LightGBM with an accuracy of 0.9715\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Compare Models and Save the Best One ---\n",
    "print(\"\\n--- Model Comparison Summary ---\")\n",
    "results_df = pd.DataFrame.from_dict(model_results, orient='index', columns=['Accuracy'])\n",
    "print(results_df.sort_values(by='Accuracy', ascending=False))\n",
    "\n",
    "best_model_name = max(model_results, key=model_results.get)\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"\\nBest performing model is: {best_model_name} with an accuracy of {model_results[best_model_name]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2524384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the best model, scaler, and encoder...\n",
      "\n",
      "Script finished successfully! ðŸŽ‰\n",
      "The best model has been saved as 'best_detection_model.joblib'.\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving the best model, scaler, and encoder...\")\n",
    "joblib.dump(best_model, 'best_detection_model.joblib')\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')\n",
    "\n",
    "print(\"\\nScript finished successfully! ðŸŽ‰\")\n",
    "print(\"The best model has been saved as 'best_detection_model.joblib'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f0b3a4",
   "metadata": {},
   "source": [
    "#### Since classes were imbalanced, we try with SMOTE now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf41dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c1833c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "filtered_df = pd.read_csv('../data/filtered_dataset.csv')\n",
    "print(\"Filtered dataset loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ac5207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8229039 entries, 0 to 8229038\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Init Fwd Win Byts  int64  \n",
      " 1   Fwd Seg Size Min   int64  \n",
      " 2   Dst Port           int64  \n",
      " 3   Fwd Header Len     int64  \n",
      " 4   Flow IAT Min       float64\n",
      " 5   Flow Duration      int64  \n",
      " 6   Fwd IAT Max        float64\n",
      " 7   Fwd IAT Min        float64\n",
      " 8   Fwd Pkts/s         float64\n",
      " 9   Flow Pkts/s        float64\n",
      " 10  Fwd IAT Tot        float64\n",
      " 11  Flow IAT Max       float64\n",
      " 12  Fwd Pkt Len Mean   float64\n",
      " 13  Fwd IAT Mean       float64\n",
      " 14  Flow IAT Mean      float64\n",
      " 15  Bwd Pkts/s         float64\n",
      " 16  Pkt Len Mean       float64\n",
      " 17  TotLen Fwd Pkts    int64  \n",
      " 18  Flow Byts/s        float64\n",
      " 19  Init Bwd Win Byts  int64  \n",
      " 20  Bwd Pkt Len Mean   float64\n",
      " 21  Bwd Pkt Len Std    float64\n",
      " 22  Bwd Pkt Len Max    int64  \n",
      " 23  Pkt Len Var        float64\n",
      " 24  Fwd Seg Size Avg   float64\n",
      " 25  Tot Fwd Pkts       int64  \n",
      " 26  Bwd Header Len     int64  \n",
      " 27  Pkt Len Max        int64  \n",
      " 28  Subflow Fwd Byts   int64  \n",
      " 29  Subflow Fwd Pkts   int64  \n",
      " 30  Label              object \n",
      "dtypes: float64(17), int64(13), object(1)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8449098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Init Fwd Win Byts</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Fwd Header Len</th>\n",
       "      <th>Flow IAT Min</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Fwd IAT Max</th>\n",
       "      <th>Fwd IAT Min</th>\n",
       "      <th>Fwd Pkts/s</th>\n",
       "      <th>Flow Pkts/s</th>\n",
       "      <th>...</th>\n",
       "      <th>Bwd Pkt Len Std</th>\n",
       "      <th>Bwd Pkt Len Max</th>\n",
       "      <th>Pkt Len Var</th>\n",
       "      <th>Fwd Seg Size Avg</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Bwd Header Len</th>\n",
       "      <th>Pkt Len Max</th>\n",
       "      <th>Subflow Fwd Byts</th>\n",
       "      <th>Subflow Fwd Pkts</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56320761.0</td>\n",
       "      <td>112641719</td>\n",
       "      <td>56320958.0</td>\n",
       "      <td>56320761.0</td>\n",
       "      <td>0.026633</td>\n",
       "      <td>0.026633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56320652.0</td>\n",
       "      <td>112641466</td>\n",
       "      <td>56320814.0</td>\n",
       "      <td>56320652.0</td>\n",
       "      <td>0.026633</td>\n",
       "      <td>0.026633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56319098.0</td>\n",
       "      <td>112638623</td>\n",
       "      <td>56319525.0</td>\n",
       "      <td>56319098.0</td>\n",
       "      <td>0.026634</td>\n",
       "      <td>0.026634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65535</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>488</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6453966</td>\n",
       "      <td>673900.0</td>\n",
       "      <td>229740.0</td>\n",
       "      <td>2.324152</td>\n",
       "      <td>3.873587</td>\n",
       "      <td>...</td>\n",
       "      <td>371.677892</td>\n",
       "      <td>976</td>\n",
       "      <td>77192.153846</td>\n",
       "      <td>82.600000</td>\n",
       "      <td>15</td>\n",
       "      <td>328</td>\n",
       "      <td>976</td>\n",
       "      <td>1239</td>\n",
       "      <td>15</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5808</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>456</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8804066</td>\n",
       "      <td>1928102.0</td>\n",
       "      <td>246924.0</td>\n",
       "      <td>1.590174</td>\n",
       "      <td>2.839597</td>\n",
       "      <td>...</td>\n",
       "      <td>362.249864</td>\n",
       "      <td>976</td>\n",
       "      <td>78267.353846</td>\n",
       "      <td>81.642857</td>\n",
       "      <td>14</td>\n",
       "      <td>360</td>\n",
       "      <td>976</td>\n",
       "      <td>1143</td>\n",
       "      <td>14</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Init Fwd Win Byts  Fwd Seg Size Min  Dst Port  Fwd Header Len  \\\n",
       "0                 -1                 0         0               0   \n",
       "1                 -1                 0         0               0   \n",
       "2                 -1                 0         0               0   \n",
       "3              65535                32        22             488   \n",
       "4               5808                32        22             456   \n",
       "\n",
       "   Flow IAT Min  Flow Duration  Fwd IAT Max  Fwd IAT Min  Fwd Pkts/s  \\\n",
       "0    56320761.0      112641719   56320958.0   56320761.0    0.026633   \n",
       "1    56320652.0      112641466   56320814.0   56320652.0    0.026633   \n",
       "2    56319098.0      112638623   56319525.0   56319098.0    0.026634   \n",
       "3          22.0        6453966     673900.0     229740.0    2.324152   \n",
       "4          21.0        8804066    1928102.0     246924.0    1.590174   \n",
       "\n",
       "   Flow Pkts/s  ...  Bwd Pkt Len Std  Bwd Pkt Len Max   Pkt Len Var  \\\n",
       "0     0.026633  ...         0.000000                0      0.000000   \n",
       "1     0.026633  ...         0.000000                0      0.000000   \n",
       "2     0.026634  ...         0.000000                0      0.000000   \n",
       "3     3.873587  ...       371.677892              976  77192.153846   \n",
       "4     2.839597  ...       362.249864              976  78267.353846   \n",
       "\n",
       "   Fwd Seg Size Avg  Tot Fwd Pkts  Bwd Header Len  Pkt Len Max  \\\n",
       "0          0.000000             3               0            0   \n",
       "1          0.000000             3               0            0   \n",
       "2          0.000000             3               0            0   \n",
       "3         82.600000            15             328          976   \n",
       "4         81.642857            14             360          976   \n",
       "\n",
       "   Subflow Fwd Byts  Subflow Fwd Pkts   Label  \n",
       "0                 0                 3  Benign  \n",
       "1                 0                 3  Benign  \n",
       "2                 0                 3  Benign  \n",
       "3              1239                15  Benign  \n",
       "4              1143                14  Benign  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ea57318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Benign                      6112151\n",
       "DDOS attack-HOIC             686012\n",
       "DoS attacks-Hulk             461912\n",
       "Bot                          286191\n",
       "FTP-BruteForce               193360\n",
       "SSH-Bruteforce               187589\n",
       "Infilteration                161934\n",
       "DoS attacks-SlowHTTPTest     139890\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "343ce338",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.columns = filtered_df.columns.str.strip()\n",
    "\n",
    "# The dataset is known to have infinity and NaN values.\n",
    "# Replace infinite values with NaN\n",
    "filtered_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# Drop rows with NaN values. For this dataset, this is a safe approach.\n",
    "filtered_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "926222cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_df.drop(columns=[\"Label\"])\n",
    "y = filtered_df['Label']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b6835be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced training script started...\n"
     ]
    }
   ],
   "source": [
    "print(\"Balanced training script started...\")\n",
    "# --- 4. Split and Scale Data ---\n",
    "# Split data BEFORE applying SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b87a045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler # Import the undersampler\n",
    "from imblearn.pipeline import Pipeline # Import the pipeline tool\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e92ffd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying a dynamic hybrid sampling strategy...\n",
      "The majority class has the numeric label: 0\n",
      "Second largest class has 548809 samples.\n",
      "Setting majority class target to 1646427 samples.\n",
      "Hybrid sampling applied. Training set is now smaller and balanced.\n",
      "New training set shape: (13171416, 30)\n",
      "Class distribution after resampling: Counter({np.int64(0): 1646427, np.int64(1): 1646427, np.int64(2): 1646427, np.int64(3): 1646427, np.int64(4): 1646427, np.int64(5): 1646427, np.int64(6): 1646427, np.int64(7): 1646427})\n"
     ]
    }
   ],
   "source": [
    "# # --- 5. Apply SMOTE to the Training Data ---\n",
    "# print(\"Applying SMOTE to the training data to handle imbalance...\")\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"SMOTE applied. Training set is now balanced.\")\n",
    "\n",
    "# --- 5. Define and Apply the Hybrid Sampling Strategy ---\n",
    "# print(\"Applying a hybrid undersampling and oversampling strategy...\")\n",
    "\n",
    "# # Define the undersampling strategy. \n",
    "# # This will reduce the 'Benign' class to have 500,000 samples. Adjust as needed.\n",
    "# # We first need to find the numerical label for 'Benign'\n",
    "# benign_label_numeric = label_encoder.transform(['Benign'])[0]\n",
    "# under_sampler = RandomUnderSampler(sampling_strategy={benign_label_numeric: 500000}, random_state=42)\n",
    "\n",
    "# # Define the SMOTE strategy. It will oversample all other classes to match the new majority.\n",
    "# over_sampler = SMOTE(random_state=42)\n",
    "\n",
    "# # Create a pipeline to apply the steps in sequence\n",
    "# pipeline = Pipeline(steps=[('u', under_sampler), ('o', over_sampler)])\n",
    "\n",
    "# # Apply the pipeline to the training data\n",
    "# X_train_resampled, y_train_resampled = pipeline.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"Hybrid sampling applied. Training set is now smaller and balanced.\")\n",
    "# print(f\"New training set shape: {X_train_resampled.shape}\")\n",
    "\n",
    "# --- 5. Define and Apply the Corrected Dynamic Hybrid Sampling Strategy ---\n",
    "print(\"Applying a dynamic hybrid sampling strategy...\")\n",
    "\n",
    "# Get the counts of each class in the training data\n",
    "class_counts = Counter(y_train)\n",
    "\n",
    "# --- THE FIX STARTS HERE ---\n",
    "# 1. Find the numeric label of the most common class (which is 'Benign')\n",
    "majority_class_label_numeric = class_counts.most_common(1)[0][0]\n",
    "print(f\"The majority class has the numeric label: {majority_class_label_numeric}\")\n",
    "\n",
    "# 2. Find the size of the second-largest class\n",
    "second_largest_class_size = sorted(class_counts.values(), reverse=True)[1]\n",
    "\n",
    "# 3. Set the undersampling target for the majority class\n",
    "majority_class_target_size = second_largest_class_size * 3\n",
    "print(f\"Second largest class has {second_largest_class_size} samples.\")\n",
    "print(f\"Setting majority class target to {majority_class_target_size} samples.\")\n",
    "# --- THE FIX ENDS HERE ---\n",
    "\n",
    "\n",
    "# Define the undersampling and oversampling strategies using the new variables\n",
    "under_sampler = RandomUnderSampler(sampling_strategy={majority_class_label_numeric: majority_class_target_size}, random_state=42)\n",
    "over_sampler = SMOTE(random_state=42)\n",
    "\n",
    "# Create and apply the pipeline\n",
    "pipeline = Pipeline(steps=[('u', under_sampler), ('o', over_sampler)])\n",
    "X_train_resampled, y_train_resampled = pipeline.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Hybrid sampling applied. Training set is now smaller and balanced.\")\n",
    "print(f\"New training set shape: {X_train_resampled.shape}\")\n",
    "print(f\"Class distribution after resampling: {Counter(y_train_resampled)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e44f811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Logistic Regression on Balanced Data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VII\\ANT\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating Logistic Regression on Original Test Data ---\n",
      "\n",
      "Accuracy for Logistic Regression: 0.5733\n",
      "Classification Report for Logistic Regression:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                  Benign       0.99      0.45      0.62   1215429\n",
      "                     Bot       0.62      1.00      0.76     57238\n",
      "        DDOS attack-HOIC       0.97      1.00      0.99    137203\n",
      "        DoS attacks-Hulk       0.98      1.00      0.99     92382\n",
      "DoS attacks-SlowHTTPTest       0.64      0.55      0.59     27978\n",
      "          FTP-BruteForce       0.71      0.78      0.74     38671\n",
      "           Infilteration       0.04      0.77      0.07     32128\n",
      "          SSH-Bruteforce       0.97      1.00      0.99     37518\n",
      "\n",
      "                accuracy                           0.57   1638547\n",
      "               macro avg       0.74      0.82      0.72   1638547\n",
      "            weighted avg       0.94      0.57      0.67   1638547\n",
      "\n",
      "\n",
      "--- Training Random Forest on Balanced Data ---\n",
      "--- Evaluating Random Forest on Original Test Data ---\n",
      "\n",
      "Accuracy for Random Forest: 0.8087\n",
      "Classification Report for Random Forest:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                  Benign       0.99      0.76      0.86   1215429\n",
      "                     Bot       1.00      1.00      1.00     57238\n",
      "        DDOS attack-HOIC       1.00      1.00      1.00    137203\n",
      "        DoS attacks-Hulk       1.00      1.00      1.00     92382\n",
      "DoS attacks-SlowHTTPTest       0.77      0.52      0.62     27978\n",
      "          FTP-BruteForce       0.72      0.88      0.79     38671\n",
      "           Infilteration       0.08      0.80      0.15     32128\n",
      "          SSH-Bruteforce       1.00      1.00      1.00     37518\n",
      "\n",
      "                accuracy                           0.81   1638547\n",
      "               macro avg       0.82      0.87      0.80   1638547\n",
      "            weighted avg       0.97      0.81      0.87   1638547\n",
      "\n",
      "\n",
      "--- Training XGBoost on Balanced Data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VII\\ANT\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating XGBoost on Original Test Data ---\n",
      "\n",
      "Accuracy for XGBoost: 0.8520\n",
      "Classification Report for XGBoost:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                  Benign       0.99      0.82      0.90   1215429\n",
      "                     Bot       1.00      1.00      1.00     57238\n",
      "        DDOS attack-HOIC       1.00      1.00      1.00    137203\n",
      "        DoS attacks-Hulk       1.00      1.00      1.00     92382\n",
      "DoS attacks-SlowHTTPTest       0.76      0.52      0.62     27978\n",
      "          FTP-BruteForce       0.72      0.88      0.79     38671\n",
      "           Infilteration       0.09      0.70      0.17     32128\n",
      "          SSH-Bruteforce       1.00      1.00      1.00     37518\n",
      "\n",
      "                accuracy                           0.85   1638547\n",
      "               macro avg       0.82      0.87      0.81   1638547\n",
      "            weighted avg       0.96      0.85      0.90   1638547\n",
      "\n",
      "\n",
      "--- Training LightGBM on Balanced Data ---\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.016258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7281\n",
      "[LightGBM] [Info] Number of data points in the train set: 13171416, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "--- Evaluating LightGBM on Original Test Data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VII\\ANT\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for LightGBM: 0.8721\n",
      "Classification Report for LightGBM:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                  Benign       0.99      0.84      0.91   1215429\n",
      "                     Bot       1.00      1.00      1.00     57238\n",
      "        DDOS attack-HOIC       1.00      1.00      1.00    137203\n",
      "        DoS attacks-Hulk       1.00      1.00      1.00     92382\n",
      "DoS attacks-SlowHTTPTest       0.93      0.53      0.68     27978\n",
      "          FTP-BruteForce       0.74      0.97      0.84     38671\n",
      "           Infilteration       0.12      0.81      0.21     32128\n",
      "          SSH-Bruteforce       1.00      1.00      1.00     37518\n",
      "\n",
      "                accuracy                           0.87   1638547\n",
      "               macro avg       0.85      0.89      0.83   1638547\n",
      "            weighted avg       0.97      0.87      0.91   1638547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Initialize Models ---\n",
    "# models = {\n",
    "#     \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "#     \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "#     \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "#     \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "# }\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=20,         # <--- LIMITS tree depth to control size\n",
    "        min_samples_leaf=5,   # <--- Prevents overfitting to small groups\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss',\n",
    "        max_depth=15,         # <--- LIMITS tree depth\n",
    "        random_state=42\n",
    "    ),\n",
    "\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        max_depth=15,         # <--- LIMITS tree depth\n",
    "        num_leaves=60,        # <--- Another way to control complexity\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "# --- 5. Train and Evaluate Each Model on Balanced Data ---\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- Training {name} on Balanced Data ---\")\n",
    "    # Train on the NEW, resampled data\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    print(f\"--- Evaluating {name} on Original Test Data ---\")\n",
    "    # Evaluate on the ORIGINAL, unbalanced test data\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    model_results[name] = accuracy\n",
    "    \n",
    "    print(f\"\\nAccuracy for {name}: {accuracy:.4f}\")\n",
    "    print(f\"Classification Report for {name}:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "958e0504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Comparison Summary (Trained on Balanced Data) ---\n",
      "                     Accuracy\n",
      "LightGBM             0.872061\n",
      "XGBoost              0.852024\n",
      "Random Forest        0.808711\n",
      "Logistic Regression  0.573322\n",
      "\n",
      "Best performing model is: LightGBM with an accuracy of 0.8721\n",
      "Saving the best model, scaler, and encoder...\n",
      "\n",
      "Script finished successfully! ðŸŽ‰\n",
      "The best model has been saved as 'best_balanced_model.joblib'.\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Compare Models and Save the Best One ---\n",
    "print(\"\\n--- Model Comparison Summary (Trained on Balanced Data) ---\")\n",
    "results_df = pd.DataFrame.from_dict(model_results, orient='index', columns=['Accuracy'])\n",
    "print(results_df.sort_values(by='Accuracy', ascending=False))\n",
    "\n",
    "best_model_name = max(model_results, key=model_results.get)\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"\\nBest performing model is: {best_model_name} with an accuracy of {model_results[best_model_name]:.4f}\")\n",
    "\n",
    "print(\"Saving the best model, scaler, and encoder...\")\n",
    "joblib.dump(best_model, 'best_balanced_model_2nd.joblib')\n",
    "joblib.dump(scaler, 'scaler_balance_2nd.joblib')\n",
    "joblib.dump(label_encoder, 'label_encoder_balanced_2nd.joblib')\n",
    "\n",
    "print(\"\\nScript finished successfully! ðŸŽ‰\")\n",
    "print(\"The best model has been saved as 'best_balanced_model.joblib'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de72059",
   "metadata": {},
   "source": [
    "#### Unsupervised Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ffcd31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score # Import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6ad68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Your Filtered Data ---\n",
    "try:\n",
    "    df = pd.read_csv('../data/filtered_dataset.csv')\n",
    "    print(\"Filtered dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'filtered_dataset.csv' not found. Please create it first.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b51feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced infinite values with NaN.\n",
      "Dropped rows with NaN values. Data is now clean.\n"
     ]
    }
   ],
   "source": [
    "# --- THE FIX STARTS HERE ---\n",
    "# 1. Replace infinite values with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "print(\"Replaced infinite values with NaN.\")\n",
    "\n",
    "# 2. Drop all rows that now contain NaN\n",
    "df.dropna(inplace=True)\n",
    "print(\"Dropped rows with NaN values. Data is now clean.\")\n",
    "# --- THE FIX ENDS HERE ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f0e1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Using full benign set for Isolation Forest: 6077145 samples.\n",
      "Using smaller benign sample for LOF and One-Class SVM: 100000 samples.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Prepare Data for Unsupervised Training ---\n",
    "print(\"Preparing data...\")\n",
    "X = df.drop(columns=['Label'])\n",
    "y = df['Label']\n",
    "\n",
    "# Create a training set with ONLY 'Benign' (normal) data\n",
    "X_train_full_benign = X[y == 'Benign']\n",
    "\n",
    "# Create a smaller sample of benign data for the slower models\n",
    "X_train_sample_benign = X_train_full_benign.sample(n=100000, random_state=42)\n",
    "print(f\"Using full benign set for Isolation Forest: {len(X_train_full_benign)} samples.\")\n",
    "print(f\"Using smaller benign sample for LOF and One-Class SVM: {len(X_train_sample_benign)} samples.\")\n",
    "\n",
    "# The test set is the entire dataset\n",
    "X_test = X\n",
    "y_test = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480e5ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Scale the Data ---\n",
    "# We fit the scaler ONLY on the full normal training data to learn the 'normal' distribution\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_full_benign)\n",
    "\n",
    "# Transform all datasets\n",
    "X_train_full_benign_scaled = scaler.transform(X_train_full_benign)\n",
    "X_train_sample_benign_scaled = scaler.transform(X_train_sample_benign)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc12d8",
   "metadata": {},
   "source": [
    "##### This is to check the percentage of the benign attacks in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43ab590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dataset Analysis ---\n",
      "Total Samples: 8192732\n",
      "Normal ('Benign') Samples: 6077145\n",
      "Anomaly (Attack) Samples: 2115587\n",
      "\n",
      "Exact Anomaly Percentage (Contamination): 0.2582\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Calculate the Percentage ---\n",
    "\n",
    "# Get the total number of rows\n",
    "total_samples = len(df)\n",
    "\n",
    "# Get the counts of each class in the 'Label' column\n",
    "label_counts = df['Label'].value_counts()\n",
    "\n",
    "# Get the number of 'Benign' (normal) samples\n",
    "benign_samples = label_counts['Benign']\n",
    "\n",
    "# The number of anomalies is everything that isn't 'Benign'\n",
    "anomaly_samples = total_samples - benign_samples\n",
    "\n",
    "# Calculate the contamination ratio (percentage of anomalies)\n",
    "contamination_ratio = anomaly_samples / total_samples\n",
    "\n",
    "# --- 3. Print the Results ---\n",
    "print(\"\\n--- Dataset Analysis ---\")\n",
    "print(f\"Total Samples: {total_samples}\")\n",
    "print(f\"Normal ('Benign') Samples: {benign_samples}\")\n",
    "print(f\"Anomaly (Attack) Samples: {anomaly_samples}\")\n",
    "print(f\"\\nExact Anomaly Percentage (Contamination): {contamination_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a57f30",
   "metadata": {},
   "source": [
    "##### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4fdb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # --- 4. Initialize Models OLD ---\n",
    "# # models = {\n",
    "# #     \"Isolation Forest\": {\n",
    "# #         \"model\": IsolationForest(n_estimators=100, contamination='auto', random_state=42, n_jobs=-1),\n",
    "# #         \"train_data\": X_train_full_benign_scaled\n",
    "# #     },\n",
    "# #     \"Local Outlier Factor\": {\n",
    "# #         # novelty=True is essential for predicting on new data\n",
    "# #         \"model\": LocalOutlierFactor(n_neighbors=20, contamination='auto', novelty=True, n_jobs=-1),\n",
    "# #         \"train_data\": X_train_sample_benign_scaled\n",
    "# #     },\n",
    "# #     \"One-Class SVM\": {\n",
    "# #         \"model\": OneClassSVM(nu=0.01, kernel=\"rbf\", gamma='auto'),\n",
    "# #         \"train_data\": X_train_sample_benign_scaled\n",
    "# #     }\n",
    "# # }\n",
    "\n",
    "# # The actual anomaly ratio in your data is ~0.25 (2,115,587 / 8,192,732)\n",
    "# known_contamination = 0.25 \n",
    "\n",
    "# models = {\n",
    "#     \"Isolation Forest\": {\n",
    "#         # FIX: Change contamination from 'auto' to the known ratio to increase sensitivity.\n",
    "#         \"model\": IsolationForest(\n",
    "#             n_estimators=100, \n",
    "#             contamination=known_contamination, #<-- THE FIX\n",
    "#             random_state=42, \n",
    "#             n_jobs=-1\n",
    "#         ),\n",
    "#         \"train_data\": X_train_full_benign_scaled\n",
    "#     },\n",
    "#     \"Local Outlier Factor\": {\n",
    "#         # TUNE: Adjust n_neighbors to fine-tune the precision/recall balance.\n",
    "#         # Start with a larger value like 30 to potentially reduce false positives.\n",
    "#         \"model\": LocalOutlierFactor(\n",
    "#             n_neighbors=30, #<-- TUNE THIS\n",
    "#             contamination=known_contamination, \n",
    "#             novelty=True, \n",
    "#             n_jobs=-1\n",
    "#         ),\n",
    "#         \"train_data\": X_train_sample_benign_scaled\n",
    "#     },\n",
    "#     \"One-Class SVM\": {\n",
    "#         # FIX: Increase 'nu' to make the model less conservative and catch more anomalies.\n",
    "#         \"model\": OneClassSVM(\n",
    "#             nu=known_contamination, #<-- THE FIX\n",
    "#             kernel=\"rbf\", \n",
    "#             gamma='auto'\n",
    "#         ),\n",
    "#         \"train_data\": X_train_sample_benign_scaled\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88625579",
   "metadata": {},
   "source": [
    "New Code for better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf11ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11629859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Known contamination ratio in dataset\n",
    "known_contamination = 0.2582  \n",
    "\n",
    "# =======================\n",
    "# Isolation Forest (IF)\n",
    "# =======================\n",
    "isolation_forest_params = {\n",
    "    \"n_estimators\": 300,      # more trees for stability\n",
    "    \"max_samples\": 0.5,       # sample half the data per tree\n",
    "    \"contamination\": known_contamination,\n",
    "    \"bootstrap\": True,        # improves variance\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# Local Outlier Factor (LOF)\n",
    "# =======================\n",
    "lof_params = {\n",
    "    \"n_neighbors\": 50,         # <-- try 20, 30, 50, 100 in sweeps\n",
    "    \"contamination\": known_contamination,\n",
    "    \"novelty\": True,           # needed for predicting on new data\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# One-Class SVM (OCSVM)\n",
    "# =======================\n",
    "# Subsample benign training data to keep memory manageable\n",
    "sample_size = 100_000\n",
    "if len(X_train_sample_benign_scaled) > sample_size:\n",
    "    X_ocsvm_train = X_train_sample_benign_scaled.sample(n=sample_size, random_state=42)\n",
    "else:\n",
    "    X_ocsvm_train = X_train_sample_benign_scaled\n",
    "\n",
    "# Option A: Simple linear kernel\n",
    "ocsvm_linear = OneClassSVM(\n",
    "    nu=known_contamination,\n",
    "    kernel=\"linear\"\n",
    ")\n",
    "\n",
    "# Option B: RBF kernel approximation + linear OCSVM\n",
    "rbf_feature = RBFSampler(gamma=1, n_components=300, random_state=42)\n",
    "ocsvm_rbf_approx = make_pipeline(\n",
    "    rbf_feature,\n",
    "    OneClassSVM(nu=known_contamination, kernel=\"linear\")\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# Collect models\n",
    "# =======================\n",
    "models = {\n",
    "    \"Isolation Forest\": {\n",
    "        \"model\": IsolationForest(**isolation_forest_params),\n",
    "        \"train_data\": X_train_full_benign_scaled\n",
    "    },\n",
    "    \"Local Outlier Factor\": {\n",
    "        \"model\": LocalOutlierFactor(**lof_params),\n",
    "        \"train_data\": X_train_sample_benign_scaled\n",
    "    },\n",
    "    \"One-Class SVM (Linear)\": {\n",
    "        \"model\": ocsvm_linear,\n",
    "        \"train_data\": X_ocsvm_train\n",
    "    },\n",
    "    \"One-Class SVM (RBF Approx)\": {\n",
    "        \"model\": ocsvm_rbf_approx,\n",
    "        \"train_data\": X_ocsvm_train\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eaaea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Isolation Forest ---\n",
      "--- Evaluating Isolation Forest ---\n",
      "*** New best model found: Isolation Forest with Anomaly F1-Score: 0.3390 ***\n",
      "\n",
      "Anomaly Detection Report for Isolation Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Anomaly (-1)       0.32      0.36      0.34   2115587\n",
      "  Normal (1)       0.77      0.74      0.75   6077145\n",
      "\n",
      "    accuracy                           0.64   8192732\n",
      "   macro avg       0.55      0.55      0.55   8192732\n",
      "weighted avg       0.65      0.64      0.65   8192732\n",
      "\n",
      "Confusion Matrix for Isolation Forest:\n",
      " [[ 751936 1363651]\n",
      " [1569119 4508026]]\n",
      "\n",
      "--- Training Local Outlier Factor ---\n",
      "--- Evaluating Local Outlier Factor ---\n",
      "*** New best model found: Local Outlier Factor with Anomaly F1-Score: 0.6701 ***\n",
      "\n",
      "Anomaly Detection Report for Local Outlier Factor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Anomaly (-1)       0.54      0.88      0.67   2115587\n",
      "  Normal (1)       0.95      0.74      0.83   6077145\n",
      "\n",
      "    accuracy                           0.78   8192732\n",
      "   macro avg       0.74      0.81      0.75   8192732\n",
      "weighted avg       0.84      0.78      0.79   8192732\n",
      "\n",
      "Confusion Matrix for Local Outlier Factor:\n",
      " [[1870616  244971]\n",
      " [1597033 4480112]]\n",
      "\n",
      "--- Training One-Class SVM (Linear) ---\n"
     ]
    }
   ],
   "source": [
    "# # --- 5. Train and Evaluate Each Model ---\n",
    "# # Convert true labels to the 1/-1 format for evaluation\n",
    "# y_test_mapped = y_test.apply(lambda x: 1 if x == 'Benign' else -1)\n",
    "\n",
    "# for name, model_info in models.items():\n",
    "#     print(f\"\\n--- Training {name} ---\")\n",
    "#     model_instance = model_info[\"model\"]\n",
    "#     train_data = model_info[\"train_data\"]\n",
    "    \n",
    "#     model_instance.fit(train_data)\n",
    "    \n",
    "#     print(f\"--- Evaluating {name} ---\")\n",
    "#     y_pred = model_instance.predict(X_test_scaled)\n",
    "    \n",
    "#     print(f\"\\nAnomaly Detection Report for {name}:\")\n",
    "#     print(classification_report(y_test_mapped, y_pred, target_names=['Anomaly (-1)', 'Normal (1)']))\n",
    "#     print(f\"Confusion Matrix for {name}:\\n\", confusion_matrix(y_test_mapped, y_pred))\n",
    "\n",
    "# print(\"\\nScript finished successfully! ðŸŽ‰\")\n",
    "\n",
    "# --- 5. Train, Evaluate, and Find the Best Model ---\n",
    "y_test_mapped = y_test.apply(lambda x: 1 if x == 'Benign' else -1)\n",
    "\n",
    "# Variables to track the best model\n",
    "best_f1_score = -1\n",
    "best_model_name = \"\"\n",
    "best_model_to_save = None\n",
    "\n",
    "for name, model_info in models.items():\n",
    "    print(f\"\\n--- Training {name} ---\")\n",
    "    model_instance = model_info[\"model\"]\n",
    "    train_data = model_info[\"train_data\"]\n",
    "    \n",
    "    model_instance.fit(train_data)\n",
    "    \n",
    "    print(f\"--- Evaluating {name} ---\")\n",
    "    y_pred = model_instance.predict(X_test_scaled)\n",
    "    \n",
    "    # --- NEW LOGIC: TRACK THE BEST MODEL ---\n",
    "    # Calculate F1-score specifically for the anomaly class (-1)\n",
    "    current_f1 = f1_score(y_test_mapped, y_pred, pos_label=-1)\n",
    "    \n",
    "    if current_f1 > best_f1_score:\n",
    "        best_f1_score = current_f1\n",
    "        best_model_name = name\n",
    "        best_model_to_save = model_instance\n",
    "        print(f\"*** New best model found: {name} with Anomaly F1-Score: {current_f1:.4f} ***\")\n",
    "    # --- END OF NEW LOGIC ---\n",
    "\n",
    "    print(f\"\\nAnomaly Detection Report for {name}:\")\n",
    "    print(classification_report(y_test_mapped, y_pred, target_names=['Anomaly (-1)', 'Normal (1)']))\n",
    "    print(f\"Confusion Matrix for {name}:\\n\", confusion_matrix(y_test_mapped, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0450a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Save the Final Best Model ---\n",
    "print(\"\\n--- Evaluation Complete ---\")\n",
    "if best_model_to_save:\n",
    "    print(f\"The best model is '{best_model_name}' with an Anomaly F1-Score of {best_f1_score:.4f}\")\n",
    "    \n",
    "    print(\"\\nSaving the best unsupervised model and its scaler...\")\n",
    "    joblib.dump(best_model_to_save, 'best_unsupervised_model.joblib')\n",
    "    joblib.dump(scaler, 'unsupervised_scaler.joblib')\n",
    "    print(\"Files saved successfully!\")\n",
    "else:\n",
    "    print(\"No model was saved as no evaluation was successful.\")\n",
    "\n",
    "print(\"\\nScript finished successfully! ðŸŽ‰\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
